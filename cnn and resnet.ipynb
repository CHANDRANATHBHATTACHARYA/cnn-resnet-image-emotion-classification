{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_EE3fk5ppKh"
   },
   "source": [
    "### Task 1: FASHION MNIST CLASSIFICATION WITH CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tbTfzEBpwXP",
    "outputId": "778c7c70-f705-4793-9639-e64997033bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 10204735.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 194182.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:06<00:00, 664653.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 15467247.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Fashion-MNIST dataset downloaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download the training dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Download the test dataset\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(\"Fashion-MNIST dataset downloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtKxmqU7DQ0N"
   },
   "source": [
    "Checking whether GPU is available or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcZ0IN8rgPzQ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7CVGJD4DfpX"
   },
   "source": [
    "Checking Particular elements of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NL1MJG9PqT4F",
    "outputId": "8aa57964-934f-4794-9f69-b69caa0eef79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image tensor: torch.Size([1, 28, 28])\n",
      "Image tensor values:\n",
      " tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000,\n",
      "          -1.0000, -0.8980, -0.4275, -1.0000, -1.0000, -0.9922, -0.9686,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -0.9922, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -1.0000,\n",
      "          -0.7176,  0.0667, -0.0039, -0.5137, -0.5765, -1.0000, -1.0000,\n",
      "          -1.0000, -0.9922, -0.9765, -0.9686, -1.0000, -1.0000, -0.9765],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -1.0000,\n",
      "          -0.2000,  0.6000,  0.3804,  0.0510,  0.1294, -0.0353, -0.8196,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9059, -0.9216, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "           0.2157,  0.8510,  0.6235,  0.3961, -0.1608,  0.2235,  0.2627,\n",
      "          -0.1451, -0.4980, -0.8196, -0.3961,  0.0196, -0.4353, -0.8824],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000, -0.4588,\n",
      "           0.6235,  0.7490,  0.7098,  0.6941,  0.6941,  0.2784, -0.0039,\n",
      "          -0.0510, -0.0431,  0.1451,  0.1059, -0.3098,  0.3490, -0.4824],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.9922, -0.9922, -0.9922, -1.0000,  0.5686,\n",
      "           0.8196,  0.8196,  0.8275,  0.7961,  0.7490,  0.7490,  0.6863,\n",
      "           0.6706,  0.2863, -0.0039, -0.0353,  0.5373,  0.7961, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.4353,\n",
      "           0.7647,  0.6941,  0.7490,  0.7882,  0.8431,  0.7804,  0.7569,\n",
      "           0.7412,  0.7569,  0.7333,  0.7490,  0.9216,  0.3569, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5137,\n",
      "           0.7882,  0.7098,  0.6706,  0.5529,  0.4118,  0.6627,  0.6471,\n",
      "           0.6549,  0.6706,  0.7490,  0.7255,  0.9059,  0.5843, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.9922, -0.9765, -1.0000, -0.9059,  0.7176,\n",
      "           0.7255,  0.6627,  0.7098,  0.5059,  0.3255,  0.7804,  0.6314,\n",
      "           0.7098,  0.7569,  0.6627,  0.7725,  0.5451,  0.6392, -0.5922],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9529, -1.0000, -0.2235,  0.9137,\n",
      "           0.7412,  0.7255,  0.7098,  0.5922,  0.5529,  0.7333,  0.6863,\n",
      "           0.6706,  0.7412,  0.7255,  0.9216, -0.0667,  0.3098, -0.5608],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.9686, -1.0000, -1.0000, -0.5686,  0.8510,\n",
      "           0.7882,  0.8039,  0.7882,  0.8824,  0.8196,  0.6706,  0.7098,\n",
      "           0.7490,  0.8353,  0.7020,  0.7020,  0.6392, -0.2784, -1.0000],\n",
      "         [-1.0000, -1.0000, -0.9922, -0.9686, -0.9529, -0.9451, -0.9843,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8588,  0.7725,\n",
      "           0.7020,  0.7490,  0.7412,  0.7176,  0.7412,  0.7333,  0.6941,\n",
      "           0.7490,  0.7961,  0.6863,  0.7098,  1.0000, -0.3961, -1.0000],\n",
      "         [-1.0000, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.5137,  0.1373,  0.6000,  0.7882,  0.6235,\n",
      "           0.6706,  0.7333,  0.7098,  0.6314,  0.6549,  0.7098,  0.7569,\n",
      "           0.7490,  0.7176,  0.6863,  0.7569,  0.9137,  0.2471, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.8588, -0.6549, -0.3569,\n",
      "          -0.1608,  0.4824,  0.7882,  0.7255,  0.7412,  0.7020,  0.7725,\n",
      "           0.5686,  0.6078,  0.6549,  0.8039,  0.7569,  0.8353,  0.3804,\n",
      "           0.4745,  0.9608,  0.9451,  0.8275,  0.8667,  0.6863, -1.0000],\n",
      "         [-1.0000, -0.5529,  0.4667,  0.6314,  0.7569,  0.7333,  0.7569,\n",
      "           0.6314,  0.6000,  0.6784,  0.6314,  0.6392,  0.5686,  0.2471,\n",
      "           0.9216,  0.5137,  0.6157,  0.7490,  1.0000,  1.0000,  0.7333,\n",
      "           0.8353,  0.7333,  0.6549,  0.7255,  0.8196,  0.9294, -1.0000],\n",
      "         [-0.9765,  0.5843,  0.7882,  0.7569,  0.7333,  0.6549,  0.6549,\n",
      "           0.6784,  0.6078,  0.6078,  0.6078,  0.7255,  0.8824, -0.3725,\n",
      "           0.1765,  1.0000,  0.7961,  0.7333,  0.4745,  0.2078,  0.4980,\n",
      "           0.6471,  0.6000,  0.6392,  0.7412,  0.7882,  0.7647, -1.0000],\n",
      "         [-0.2314,  0.8275,  0.5529,  0.6471,  0.7412,  0.7961,  0.7961,\n",
      "           0.8353,  0.9529,  0.7255,  0.5216,  0.6863,  0.7020,  0.8902,\n",
      "          -0.4902, -0.4275, -0.1686, -0.0824,  0.3176,  0.7176,  0.7333,\n",
      "           0.6863,  0.7020,  0.7490,  0.7490,  0.7569,  0.7961, -0.7725],\n",
      "         [-0.4118,  0.6000,  0.6627,  0.6000,  0.5137,  0.6078,  0.6549,\n",
      "           0.7647,  0.6941,  0.4510,  0.5451,  0.6157,  0.5529,  0.6706,\n",
      "           0.8824,  0.5294,  0.7804,  0.9216,  0.8745,  0.7490,  0.7098,\n",
      "           0.6627,  0.6392,  0.7412,  0.7255,  0.7333,  0.8039, -0.4745],\n",
      "         [-0.6235,  0.5922,  0.4353,  0.5216,  0.6706,  0.5451,  0.4510,\n",
      "           0.4902,  0.5216,  0.5059,  0.5843,  0.6784,  0.7176,  0.7333,\n",
      "           0.7255,  0.8510,  0.7647,  0.6941,  0.5608,  0.6157,  0.4588,\n",
      "           0.4196,  0.3882,  0.3490,  0.4196,  0.6078,  0.6157, -0.0980],\n",
      "         [-1.0000, -0.0431,  0.7176,  0.5137,  0.4039,  0.3412,  0.4353,\n",
      "           0.5373,  0.6000,  0.6471,  0.6706,  0.6235,  0.6549,  0.6471,\n",
      "           0.5686,  0.5373,  0.5216,  0.4980,  0.5294,  0.4980,  0.5529,\n",
      "           0.5059,  0.3804,  0.2235,  0.3098,  0.3882,  0.6471, -0.2784],\n",
      "         [-1.0000, -1.0000, -0.4196,  0.4824,  0.6627,  0.4980,  0.3725,\n",
      "           0.3490,  0.3725,  0.4196,  0.4510,  0.4745,  0.4824,  0.4745,\n",
      "           0.5137,  0.5529,  0.6000,  0.6392,  0.6471,  0.6471,  0.6549,\n",
      "           0.4745,  0.4745,  0.5216,  0.5059,  0.6941,  0.3333, -1.0000],\n",
      "         [-0.9843, -1.0000, -1.0000, -1.0000, -0.4824,  0.5686,  0.7412,\n",
      "           0.8588,  0.8745,  0.8980,  0.9294,  0.9059,  0.9137,  0.7333,\n",
      "           0.7255,  0.5137,  0.4980,  0.4039,  0.4275,  0.4275,  0.4196,\n",
      "           0.3804,  0.3020,  0.3176, -0.2235, -0.5451, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.6863, -0.5216, -0.6549, -0.4353, -0.6784, -0.7255, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])\n",
      "\n",
      "Label: 9\n",
      "Is the image a 3D tensor? True\n",
      "Shape of the image tensor: torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Get the first sample from the training dataset\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "# Print the shape and values of the image tensor\n",
    "print(f\"Shape of the image tensor: {image.shape}\")\n",
    "print(\"Image tensor values:\\n\", image)\n",
    "\n",
    "# Print the label of the image\n",
    "print(f\"\\nLabel: {label}\")\n",
    "# Get the first sample from the training dataset\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "# Check if the image is a 3D tensor\n",
    "is_3d = len(image.shape) == 3\n",
    "\n",
    "print(f\"Is the image a 3D tensor? {is_3d}\")\n",
    "print(f\"Shape of the image tensor: {image.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpfCkPKlDyPe"
   },
   "source": [
    "Check the type and structure of elements in train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMovt6U9sg5Y",
    "outputId": "d451ae53-bdde-4c69-d433-3b5efbe32ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "Image type: <class 'torch.Tensor'>\n",
      "Label type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset[0]))\n",
    "print(f\"Image type: {type(train_dataset[0][0])}\")\n",
    "print(f\"Label type: {type(train_dataset[0][1])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJwO3_3QD5L9"
   },
   "source": [
    "Relabeling the images as per the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTRq3Tv4rzlM",
    "outputId": "754a302d-0a02-47db-acbe-3c3487e18758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Label: 9, New Label: 1\n",
      "Original Label: 0, New Label: 0\n",
      "Original Label: 0, New Label: 0\n",
      "Original Label: 3, New Label: 0\n",
      "Original Label: 0, New Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping for new labels\n",
    "def relabel(label):\n",
    "    # Clothes: 0\n",
    "    if label in [0, 1, 2, 3, 4, 6]:\n",
    "        return 0\n",
    "    # Shoes: 1\n",
    "    elif label in [5, 7, 9]:\n",
    "        return 1\n",
    "    # Others: 2\n",
    "    elif label == 8:\n",
    "        return 2\n",
    "\n",
    "train_dataset_relabel = [(image, relabel(label)) for image, label in train_dataset]\n",
    "test_dataset_relabel = [(image, relabel(label)) for image, label in test_dataset]\n",
    "\n",
    "# Check the first few relabeled samples\n",
    "for i in range(5):\n",
    "    image, new_label = train_dataset_relabel[i]\n",
    "    print(f\"Original Label: {train_dataset[i][1]}, New Label: {new_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtH3VxlhEDkV"
   },
   "source": [
    "Constructing the CNN Model to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBj996QiZoph",
    "outputId": "46ce2906-8d7f-4cb4-8bf1-f1e612e3c6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.4, inplace=False)\n",
      "    (16): AdaptiveAvgPool2d(output_size=1)\n",
      "    (17): Flatten(start_dim=1, end_dim=-1)\n",
      "    (18): Linear(in_features=256, out_features=3, bias=True)\n",
      "    (19): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            # Layer 0: Convolutional Layer with kernel size 5\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Pooling layer to reduce spatial size\n",
    "\n",
    "            # Layer 1: Convolutional Layer with kernel size 3\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Pooling layer to reduce spatial size\n",
    "\n",
    "            # Layer 2: Convolutional Layer with kernel size 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Pooling layer to reduce spatial size\n",
    "\n",
    "            # Layer 3: Convolutional Layer with kernel size 1 (1x1 convolution)\n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Dropout layer for regularization\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            # Layer 4: Global Average Pooling\n",
    "            nn.AdaptiveAvgPool2d(1),  # Reduces each channel to a single value\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # Fully Connected Layer\n",
    "            nn.Linear(256, output_size),  # Final layer with the number of classes\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Create the new custom CNN model instance\n",
    "input_size = 1  # Single channel (grayscale) images\n",
    "output_size = 3  # Three categories: Clothes, Shoes, Others\n",
    "model = CNN(input_size, output_size)\n",
    "\n",
    "# Print the new model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9L55RZlEMEn"
   },
   "source": [
    "Training the model with the relabelled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk3zPcwOZ7BR",
    "outputId": "19a3d837-d8ed-42df-e7fd-ba38c2445e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0370\n",
      "Epoch 2/10, Loss: 0.0148\n",
      "Epoch 3/10, Loss: 0.0109\n",
      "Epoch 4/10, Loss: 0.0082\n",
      "Epoch 5/10, Loss: 0.0064\n",
      "Epoch 6/10, Loss: 0.0057\n",
      "Epoch 7/10, Loss: 0.0049\n",
      "Epoch 8/10, Loss: 0.0038\n",
      "Epoch 9/10, Loss: 0.0042\n",
      "Epoch 10/10, Loss: 0.0024\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if CUDA is available and use it if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move the model to the device\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create DataLoader objects for training and test sets\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset_relabel, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_relabel, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to the device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDpQCq9mEe-P"
   },
   "source": [
    "Checking the model accuracy on the relabelled test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62aiTQ93euBq",
    "outputId": "57b57e3f-ead5-4d42-a6db-44c85254df1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 99.65%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)  # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CN09bNP1OlHM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1JARQBcEypk"
   },
   "source": [
    "Permuting the training and test data set with a fixed permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIgpI1ZMfily"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Create a permutation index for 28x28 pixels\n",
    "permute_idx = np.random.permutation(28 * 28)\n",
    "\n",
    "# Define a custom transform that permutes pixels\n",
    "class PermuteTransform:\n",
    "    def __init__(self, permute_idx):\n",
    "        self.permute_idx = permute_idx\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = image.view(-1)\n",
    "        image = image[self.permute_idx]\n",
    "        return image.view(1, 28, 28)\n",
    "\n",
    "# Create a permuted version of the dataset\n",
    "permuted_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    PermuteTransform(permute_idx)\n",
    "])\n",
    "\n",
    "# Create permuted train and test datasets\n",
    "train_dataset_permuted = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=permuted_transform\n",
    ")\n",
    "\n",
    "test_dataset_permuted = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=permuted_transform\n",
    ")\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 64\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJC-4EmiFMBC"
   },
   "source": [
    "Again Relabelling the training and the test set as per the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhT9SePNhxlf"
   },
   "outputs": [],
   "source": [
    "def relabel(label):\n",
    "    if label in [0, 1, 2, 3, 4, 6]:\n",
    "        return 0  # Clothes\n",
    "    elif label in [5, 7, 9]:\n",
    "        return 1  # Shoes\n",
    "    elif label == 8:\n",
    "        return 2  # Others\n",
    "\n",
    "# Relabel the permuted train and test datasets\n",
    "train_dataset_permuted_relabel = [(image, relabel(label)) for image, label in train_dataset_permuted]\n",
    "test_dataset_permuted_relabel = [(image, relabel(label)) for image, label in test_dataset_permuted]\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Create DataLoader for relabeled permuted datasets\n",
    "train_loader_permuted_relabel = DataLoader(train_dataset_permuted_relabel, batch_size=batch_size, shuffle=True)\n",
    "test_loader_permuted_relabel = DataLoader(test_dataset_permuted_relabel, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmDrD56MFV3w"
   },
   "source": [
    "Training the model with the permuted and relabelled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss2kCA_mfmg1",
    "outputId": "55441fdf-6b8d-4932-89fa-3899ce4100d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuted Relabeled Epoch 1/10, Loss: 0.0616\n",
      "Permuted Relabeled Epoch 2/10, Loss: 0.0264\n",
      "Permuted Relabeled Epoch 3/10, Loss: 0.0169\n",
      "Permuted Relabeled Epoch 4/10, Loss: 0.0128\n",
      "Permuted Relabeled Epoch 5/10, Loss: 0.0097\n",
      "Permuted Relabeled Epoch 6/10, Loss: 0.0076\n",
      "Permuted Relabeled Epoch 7/10, Loss: 0.0064\n",
      "Permuted Relabeled Epoch 8/10, Loss: 0.0051\n",
      "Permuted Relabeled Epoch 9/10, Loss: 0.0045\n",
      "Permuted Relabeled Epoch 10/10, Loss: 0.0043\n",
      "Training on relabeled permuted data complete!\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize the model for training on relabeled permuted data\n",
    "model_permuted_relabel = CNN(input_size, output_size)\n",
    "model_permuted_relabel.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer_permuted_relabel = optim.Adam(model_permuted_relabel.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model on relabeled permuted dataset\n",
    "for epoch in range(epochs):\n",
    "    model_permuted_relabel.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader_permuted_relabel:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer_permuted_relabel.zero_grad()\n",
    "        outputs = model_permuted_relabel(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_permuted_relabel.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Permuted Relabeled Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader_permuted_relabel):.4f}\")\n",
    "\n",
    "print(\"Training on relabeled permuted data complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h05EfWnPFfEO"
   },
   "source": [
    "Checking the classification accuracy on the relabelled training and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfBwN13cnMU3",
    "outputId": "9b77a658-cda7-4747-9cbc-dd0c6431ab8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the relabeled permuted test set: 98.99%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the relabeled permuted test set\n",
    "model_permuted_relabel.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_permuted_relabel:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_permuted_relabel(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_permuted_relabel = 100 * correct / total\n",
    "print(f\"Accuracy on the relabeled permuted test set: {accuracy_permuted_relabel:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6jYlgj8F0xP"
   },
   "source": [
    "### Task 2: RESNET for Emotion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic6J2IGOGCO6"
   },
   "source": [
    "The required data is uploading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "6AgEOtL2g-rv",
    "outputId": "93f4541a-8771-428f-dd1c-106fd2fc0967"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5c54291c-50bf-45eb-ae22-9b50b42f1490\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-5c54291c-50bf-45eb-ae22-9b50b42f1490\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving emotion_detection_dataset.zip to emotion_detection_dataset.zip\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ar_FJi_GIKF"
   },
   "source": [
    "unzipping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0fJDawNlbnH"
   },
   "outputs": [],
   "source": [
    "!unzip -q emotion_detection_dataset.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWGKHGbgmJIF",
    "outputId": "d37164c0-3eb8-4994-c7e3-5cfacf63daca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config',\n",
       " 'emotion_detection_dataset',\n",
       " 'emotion_detection_dataset.zip',\n",
       " 'sample_data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hwuqs57mNTO",
    "outputId": "826a917f-f490-4623-aa67-bd1c895e6b33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config',\n",
       " 'emotion_detection_dataset',\n",
       " 'emotion_detection_dataset.zip',\n",
       " 'sample_data']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the contents of the current directory\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRQ1TV4umwCX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9s9AHkeGSE8"
   },
   "source": [
    "Transforming the images in a size as the requirements and normalizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I77Nz2RsujXW"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUGaSDBrulLt"
   },
   "outputs": [],
   "source": [
    "# Paths to the train and test directories\n",
    "train_dir = './emotion_detection_dataset/train'\n",
    "test_dir = './emotion_detection_dataset/test'\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "rPptY8x4u80P",
    "outputId": "b9300d51-0677-437f-e7ad-507fc632d7b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
       "\n",
       "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
       "iterable-style datasets with single- or multi-process loading, customizing\n",
       "loading order and optional automatic batching (collation) and memory pinning.\n",
       "\n",
       "See :py:mod:`torch.utils.data` documentation page for more details.\n",
       "\n",
       "Args:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: ``1``).\n",
       "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
       "        at every epoch (default: ``False``).\n",
       "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
       "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
       "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
       "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
       "        returns a batch of indices at a time. Mutually exclusive with\n",
       "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
       "        and :attr:`drop_last`.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. ``0`` means that the data will be loaded in the main process.\n",
       "        (default: ``0``)\n",
       "    collate_fn (Callable, optional): merges a list of samples to form a\n",
       "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
       "        map-style dataset.\n",
       "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
       "        into device/CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: ``False``)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: ``0``)\n",
       "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
       "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
       "        input, after seeding and before data loading. (default: ``None``)\n",
       "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
       "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
       "        be used. (default: ``None``)\n",
       "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
       "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
       "        ``base_seed`` for workers. (default: ``None``)\n",
       "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
       "        in advance by each worker. ``2`` means there will be a total of\n",
       "        2 * num_workers batches prefetched across all workers. (default value depends\n",
       "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
       "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
       "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
       "        the worker processes after a dataset has been consumed once. This allows to\n",
       "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
       "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
       "        ``True``.\n",
       "\n",
       "\n",
       ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
       "             cannot be an unpicklable object, e.g., a lambda function. See\n",
       "             :ref:`multiprocessing-best-practices` on more details related\n",
       "             to multiprocessing in PyTorch.\n",
       "\n",
       ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
       "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
       "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
       "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
       "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
       "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
       "             loading to avoid duplicate data.\n",
       "\n",
       "             However, if sharding results in multiple workers having incomplete last batches,\n",
       "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
       "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
       "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
       "             cases in general.\n",
       "\n",
       "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
       "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
       "             `Multi-process data loading`_.\n",
       "\n",
       ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
       "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
       "\n",
       ".. _multiprocessing context:\n",
       "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 125);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDFmyqGNvaTb"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CQChh8IGl9X"
   },
   "source": [
    "Initializing a Resnet18 network to train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPSiga-pvelG",
    "outputId": "7aee21cf-d052-42f8-df1a-6ea9cca39e4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ResNet-18 model\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "num_classes = len(train_dataset.classes)  # Number of classes in your dataset\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ES564kXhvj2E",
    "outputId": "0ae0ae43-0920-4f1c-9a4b-4b78c77097e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elKF1LmPvyZV",
    "outputId": "a0b6e4ff-0098-475c-f8b7-8709cc1deda6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28709"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OOghajSv1jb",
    "outputId": "7a06ea05-5ace-4b1d-a057-51a10da08d57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seQKkC-OCioU",
    "outputId": "4a6c749a-6f90-403c-9201-2447d576c1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and ready to use!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available and ready to use!\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHhAjguOv8uR"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNhhoHvewGZR"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUR30qfrwTn3"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgA9rF58Gth_"
   },
   "source": [
    "Training the untrained Resnet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXLENzY9wWZe",
    "outputId": "cf081f82-6fda-4e9f-83f0-9177e6a28068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.7590\n",
      "Epoch [2/10], Loss: 1.3933\n",
      "Epoch [3/10], Loss: 1.2228\n",
      "Epoch [4/10], Loss: 1.1161\n",
      "Epoch [5/10], Loss: 1.0285\n",
      "Epoch [6/10], Loss: 0.9385\n",
      "Epoch [7/10], Loss: 0.8282\n",
      "Epoch [8/10], Loss: 0.6951\n",
      "Epoch [9/10], Loss: 0.5273\n",
      "Epoch [10/10], Loss: 0.3726\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9Jcx5vQGzdZ"
   },
   "source": [
    "Checking performabce on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ro6Nu2HdGXUM",
    "outputId": "fee8ced5-331c-49e8-eca8-245c4365d8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 60.14%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6RTYRFcHCMI"
   },
   "source": [
    "Now fine tuning a pretrained Resnet18 classifier which is in built in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUYwWQBHHAMk",
    "outputId": "26853f60-59a1-4636-ee88-6270c200ef2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet-18 model\n",
    "model_pretrained = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final fully connected layer\n",
    "num_features = model_pretrained.fc.in_features\n",
    "model_pretrained.fc = nn.Linear(num_features, num_classes)  # Adjusting for the number of classes in the dataset\n",
    "\n",
    "model_pretrained = model_pretrained.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dSEN4SkHCe6"
   },
   "outputs": [],
   "source": [
    "optimizer_pretrained = optim.Adam(model_pretrained.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLrKRF6BHI_F"
   },
   "source": [
    "Training on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxkQoocUHFeD",
    "outputId": "7f3c51ae-2e4e-4630-94e3-a97a219d6e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5947\n",
      "Epoch [2/10], Loss: 1.5002\n",
      "Epoch [3/10], Loss: 1.4699\n",
      "Epoch [4/10], Loss: 1.4537\n",
      "Epoch [5/10], Loss: 1.4508\n",
      "Epoch [6/10], Loss: 1.4460\n",
      "Epoch [7/10], Loss: 1.4426\n",
      "Epoch [8/10], Loss: 1.4393\n",
      "Epoch [9/10], Loss: 1.4330\n",
      "Epoch [10/10], Loss: 1.4319\n",
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_pretrained.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer_pretrained.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model_pretrained(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_pretrained.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "print(\"Fine-tuning complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "we1tel1hHNiL"
   },
   "source": [
    "Checking it's accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0zyw7aaJYHA",
    "outputId": "a5e0d2ca-57ee-4c9e-9b69-b827d600121c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the fine-tuned model on the test set: 45.61%\n"
     ]
    }
   ],
   "source": [
    "model_pretrained.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_pretrained(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the fine-tuned model on the test set: {accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
